import os
from typing import List, Union, Optional
import fastmcp
# æ‰“å°fastmcpçš„ç‰ˆæœ¬
print(f"FastMCP Version: {fastmcp.__version__}")
from fastmcp import FastMCP
from pydantic import BaseModel, Field
from starlette.requests import Request
from starlette.responses import FileResponse, JSONResponse

# åŠ è½½é…ç½®
from config import (
    OUTPUT_DIR,
    PUBLIC_FILE_BASE_URL,
    BASE_URL,
    SERVER_HOST,
    SERVER_PORT,
    SERVER_PATH,
    SERVER_TRANSPORT,
    SERVER_LOG_LEVEL
)
print(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
print(f"OUTPUT_DIR ç»å¯¹è·¯å¾„: {os.path.abspath(OUTPUT_DIR)}")

from cleanup import start_cleanup_scheduler

# å¯¼å…¥å·¥å…·å‡½æ•°
from mcp_tools.multiple_regression_tool import perform_multiple_regression
from mcp_tools.stepwise_regression_tool import perform_stepwise_regression
from mcp_tools.hotelling_t2_tool import perform_hotelling_t2_test
from mcp_tools.multivariate_normality_tool import perform_multivariate_normality_test
from mcp_tools.covariance_homogeneity_tool import perform_covariance_homogeneity_test
from mcp_tools.manova_tool import perform_manova
from mcp_tools.box_m_test_tool import perform_box_m_test
from mcp_tools.categorical_independence_test_tool import perform_categorical_independence_test
from mcp_tools.continuous_independence_test_tool import perform_continuous_independence_test
from mcp_tools.fisher_discriminant_analysis_tool import perform_fisher_discriminant_analysis
from mcp_tools.distance_discriminant_analysis_tool import perform_distance_discriminant_analysis
from mcp_tools.bayes_discriminant_analysis_tool import perform_bayes_discriminant_analysis
from mcp_tools.generalized_square_distance_discriminant_analysis_tool import perform_generalized_square_distance_discriminant_analysis
from mcp_tools.stepwise_discriminant_analysis_tool import perform_stepwise_discriminant_analysis
# æ·»åŠ èšç±»åˆ†æå·¥å…·å¯¼å…¥
from mcp_tools.kmeans_clustering_tool import perform_kmeans_clustering
from mcp_tools.kmedoids_clustering_tool import perform_kmedoids_clustering
from mcp_tools.dbscan_clustering_tool import perform_dbscan_clustering
from mcp_tools.hierarchical_clustering_tool import perform_hierarchical_clustering
from mcp_tools.gmm_clustering_tool import perform_gmm_clustering
# æ·»åŠ ä¸»æˆåˆ†åˆ†æå·¥å…·å¯¼å…¥
from mcp_tools.pca_tool import perform_pca
# æ·»åŠ å› å­åˆ†æå·¥å…·å¯¼å…¥
from mcp_tools.factor_analysis_tool import perform_factor_analysis
# æ·»åŠ å¯¹åº”åˆ†æå·¥å…·å¯¼å…¥
from mcp_tools.correspondence_analysis_tool import perform_correspondence_analysis
# æ·»åŠ å…¸å‹ç›¸å…³åˆ†æå·¥å…·å¯¼å…¥
from mcp_tools.canonical_correlation_analysis_tool import perform_canonical_correlation_analysis
# æ·»åŠ åæœ€å°äºŒä¹˜å›å½’åˆ†æå·¥å…·å¯¼å…¥
from mcp_tools.pls_regression_tool import perform_pls_regression
# æ·»åŠ æ—¶é—´åºåˆ—åˆ†æå·¥å…·å¯¼å…¥
from mcp_tools.time_series_analysis_tool import perform_time_series_analysis
# æ·»åŠ æ—¶é—´åºåˆ—é¢„å¤„ç†æ£€éªŒå·¥å…·å¯¼å…¥
from mcp_tools.time_series_preprocessing_test_tool import perform_time_series_preprocessing_tests
# æ·»åŠ æ­£åˆ™åŒ–å›å½’å·¥å…·å¯¼å…¥
from mcp_tools.regularized_regression_tool import perform_regularized_regression
# æ·»åŠ å¹¿ä¹‰çº¿æ€§æ¨¡å‹å·¥å…·å¯¼å…¥
from mcp_tools.generalized_linear_model_tool import perform_generalized_linear_model
# æ·»åŠ ç»“æ„æ–¹ç¨‹æ¨¡å‹å·¥å…·å¯¼å…¥
from mcp_tools.sem_tool import perform_sem
# æ·»åŠ åˆ†ä½æ•°å›å½’å·¥å…·å¯¼å…¥
from mcp_tools.quantile_regression_tool import perform_quantile_regression
# æ·»åŠ å¤šç»´å°ºåº¦åˆ†æå·¥å…·å¯¼å…¥
from mcp_tools.mds_tool import perform_mds
# æ·»åŠ UMAPéçº¿æ€§é™ç»´å·¥å…·å¯¼å…¥
from mcp_tools.umap_tool import perform_umap
# æ·»åŠ ç¨³å¥å›å½’å·¥å…·å¯¼å…¥
from mcp_tools.robust_regression_tool import perform_robust_regression
# æ·»åŠ HDBSCANèšç±»å·¥å…·å¯¼å…¥
from mcp_tools.hdbscan_clustering_tool import perform_hdbscan_clustering
# æ·»åŠ æ—¶é—´åºåˆ—åæ•´å’ŒGrangerå› æœæ£€éªŒå·¥å…·å¯¼å…¥
from mcp_tools.time_series_cointegration_granger_tool import perform_time_series_cointegration_granger_tests
# æ·»åŠ æ•°æ®æ ‡å‡†åŒ–å·¥å…·å¯¼å…¥
from mcp_tools.data_standardization_tool import perform_data_standardization
# æ·»åŠ å¤šé‡å…±çº¿æ€§è¯Šæ–­å·¥å…·å¯¼å…¥
from mcp_tools.multicollinearity_diagnosis_tool import perform_multicollinearity_diagnosis
# æ·»åŠ æ··åˆæ•ˆåº”æ¨¡å‹å·¥å…·å¯¼å…¥
from mcp_tools.mixed_effects_model_tool import perform_mixed_effects_model
# æ·»åŠ å¤šé‡æ’è¡¥å·¥å…·å¯¼å…¥
from mcp_tools.multiple_imputation_tool import perform_multiple_imputation
# æ·»åŠ ç”Ÿå­˜åˆ†æå·¥å…·å¯¼å…¥
from mcp_tools.survival_analysis_tool import perform_survival_analysis
# æ·»åŠ å› æœæ¨æ–­å·¥å…·å¯¼å…¥
from mcp_tools.causal_inference_tool import perform_causal_inference
# æ·»åŠ éå‚æ•°å›å½’å·¥å…·å¯¼å…¥
from mcp_tools.nonparametric_regression_tool import perform_nonparametric_regression

# æ·»åŠ æ•°æ®åˆ†ææ‰€éœ€åº“
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
import uuid
import json

# ========== åˆå§‹åŒ– FastMCP ==========
mcp = FastMCP("multivariate-statistics-mcp-server ğŸ“Š")

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
os.makedirs(OUTPUT_DIR, exist_ok=True)
# å°è¯•å†™ä¸€ä¸ªæµ‹è¯•æ–‡ä»¶ï¼Œç¡®ä¿è¾“å‡ºç›®å½•å¯å†™
test_file = os.path.join(OUTPUT_DIR, ".write_test")
try:
    with open(test_file, "w") as f:
        f.write("ok")
    os.remove(test_file)
except Exception as e:
    print(f"FATAL: æ— æ³•å†™å…¥ {OUTPUT_DIR}: {e}")
    exit(1)

# ===================== å·¥å…·å‡½æ•°å®šä¹‰ï¼ˆå‚æ•°ç›´æ¥å®šä¹‰åœ¨å‡½æ•°ç­¾åä¸­ï¼‰ =====================

@mcp.tool()
def perform_multiple_regression_tool(
    dependent_var: List[float] = Field(..., description="å› å˜é‡æ•°æ®"),
    independent_vars: List[float] = Field(..., description="è‡ªå˜é‡æ•°æ®ï¼Œæ‰€æœ‰è‡ªå˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨ï¼Œç¬¬ä¸€ä¸ªä¸ºå› å˜é‡åï¼Œåç»­ä¸ºè‡ªå˜é‡å"),
):
    """
    æ‰§è¡Œå¤šå…ƒçº¿æ€§å›å½’åˆ†æï¼ŒåŒ…å«ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒå’Œæ®‹å·®åˆ†æ
    """
    return perform_multiple_regression(dependent_var, independent_vars, var_names)

@mcp.tool()
def perform_stepwise_regression_tool(
    dependent_var: List[float] = Field(..., description="å› å˜é‡æ•°æ®"),
    independent_vars: List[float] = Field(..., description="è‡ªå˜é‡æ•°æ®ï¼Œæ‰€æœ‰è‡ªå˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨ï¼Œç¬¬ä¸€ä¸ªä¸ºå› å˜é‡åï¼Œåç»­ä¸ºè‡ªå˜é‡å"),
    method: str = Field("both", description="é€æ­¥å›å½’æ–¹æ³•(å¯é€‰): 'forward'(å‘å‰), 'backward'(å‘å), 'both'(åŒå‘)"),
    significance_level_enter: float = Field(0.05, description="å˜é‡è¿›å…¥æ¨¡å‹çš„æ˜¾è‘—æ€§æ°´å¹³(å¯é€‰)"),
    significance_level_remove: float = Field(0.10, description="å˜é‡ç§»å‡ºæ¨¡å‹çš„æ˜¾è‘—æ€§æ°´å¹³(å¯é€‰)"),
):
    """
    æ‰§è¡Œé€æ­¥å›å½’åˆ†æï¼ŒåŒ…å«ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒå’Œæ®‹å·®åˆ†æ
    """
    return perform_stepwise_regression(
        dependent_var, 
        independent_vars, 
        var_names, 
        method, 
        significance_level_enter, 
        significance_level_remove
    )

@mcp.tool()
def perform_hotelling_t2_test_tool(
    group1_data: List[float] = Field(..., description="ç¬¬ä¸€ç»„æ ·æœ¬æ•°æ®ï¼Œæ‰€æœ‰å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    group2_data: List[float] = Field(..., description="ç¬¬äºŒç»„æ ·æœ¬æ•°æ®ï¼Œæ‰€æœ‰å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
):
    """
    æ‰§è¡ŒHotelling's TÂ²æ£€éªŒï¼Œç”¨äºæ£€éªŒä¸¤ä¸ªå¤šç»´æ­£æ€åˆ†å¸ƒæ€»ä½“çš„å‡å€¼å‘é‡æ˜¯å¦ç›¸ç­‰
    """
    return perform_hotelling_t2_test(group1_data, group2_data, var_names)

@mcp.tool()
def perform_multivariate_normality_test_tool(
    data: List[float] = Field(..., description="æ ·æœ¬æ•°æ®ï¼Œæ‰€æœ‰å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
):
    """
    æ‰§è¡Œå¤šå…ƒæ­£æ€æ€§æ£€éªŒï¼Œæ£€éªŒå¤šå˜é‡æ•°æ®æ˜¯å¦ç¬¦åˆå¤šå…ƒæ­£æ€åˆ†å¸ƒ
    """
    return perform_multivariate_normality_test(data, var_names)

@mcp.tool()
def perform_covariance_homogeneity_test_tool(
    groups_data: List[float] = Field(..., description="å¤šç»„æ ·æœ¬æ•°æ®ï¼Œæ‰€æœ‰ç»„å’Œå˜é‡çš„å€¼æŒ‰ç»„å’Œå˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(å…ˆæ”¾ç»„1çš„ X1ã€X2...ï¼Œå†æ”¾ç»„2çš„X1ã€X2...)"),
    group_names: List[str] = Field(..., description="ç»„åç§°åˆ—è¡¨"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
):
    """
    æ‰§è¡Œåæ–¹å·®çŸ©é˜µé½æ€§æ£€éªŒ(Bartlettæ£€éªŒ)ï¼Œç”¨äºæ£€éªŒå¤šä¸ªå¤šå…ƒæ­£æ€åˆ†å¸ƒæ€»ä½“çš„åæ–¹å·®çŸ©é˜µæ˜¯å¦ç›¸ç­‰
    """
    return perform_covariance_homogeneity_test(groups_data, group_names, var_names)

@mcp.tool()
def perform_manova_tool(
    groups_data: List[float] = Field(..., description="å¤šç»„æ ·æœ¬æ•°æ®ï¼Œæ‰€æœ‰ç»„å’Œå˜é‡çš„å€¼æŒ‰ç»„å’Œå˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(å…ˆæ”¾ç»„1çš„ X1ã€X2...ï¼Œå†æ”¾ç»„2çš„X1ã€X2...)"),
    group_names: List[str] = Field(..., description="ç»„åç§°åˆ—è¡¨"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
):
    """
    æ‰§è¡Œå¤šå…ƒæ–¹å·®åˆ†æ(MANOVA)ï¼Œç”¨äºæ£€éªŒå¤šä¸ªç»„åœ¨å¤šä¸ªå› å˜é‡ä¸Šçš„å‡å€¼å‘é‡æ˜¯å¦å­˜åœ¨æ˜¾è‘—å·®å¼‚
    """
    return perform_manova(groups_data, group_names, var_names)

@mcp.tool()
def perform_box_m_test_tool(
    groups_data: List[float] = Field(..., description="å¤šç»„æ ·æœ¬æ•°æ®ï¼Œæ‰€æœ‰ç»„å’Œå˜é‡çš„å€¼æŒ‰ç»„å’Œå˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(å…ˆæ”¾ç»„1çš„ X1ã€X2...ï¼Œå†æ”¾ç»„2çš„X1ã€X2...)"),
    group_names: List[str] = Field(..., description="ç»„åç§°åˆ—è¡¨"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
):
    """
    æ‰§è¡ŒBox's Mæ£€éªŒï¼Œç”¨äºæ£€éªŒå¤šä¸ªå¤šå…ƒæ­£æ€åˆ†å¸ƒæ€»ä½“çš„åæ–¹å·®çŸ©é˜µæ˜¯å¦ç›¸ç­‰
    """
    return perform_box_m_test(groups_data, group_names, var_names)

@mcp.tool()
def perform_categorical_independence_test_tool(
    observed_frequencies: List[int] = Field(..., description="è§‚æµ‹é¢‘æ•°è¡¨ï¼Œæ‰€æœ‰è¡Œçš„å€¼æŒ‰è¡Œæ‹¼æ¥æˆä¸€ç»´æ•°ç»„(å…ˆæ”¾ç¬¬1è¡Œçš„å€¼ï¼Œå†æ”¾ç¬¬2è¡Œçš„å€¼ï¼Œ...)"),
    row_labels: List[str] = Field(..., description="è¡Œæ ‡ç­¾åˆ—è¡¨"),
    col_labels: List[str] = Field(..., description="åˆ—æ ‡ç­¾åˆ—è¡¨"),
):
    """
    æ‰§è¡Œå¡æ–¹ç‹¬ç«‹æ€§æ£€éªŒï¼Œç”¨äºæ£€éªŒä¸¤ä¸ªåˆ†ç±»å˜é‡æ˜¯å¦ç›¸äº’ç‹¬ç«‹
    """
    return perform_categorical_independence_test(observed_frequencies, row_labels, col_labels)

@mcp.tool()
def perform_continuous_independence_test_tool(
    data: List[float] = Field(..., description="è¿ç»­å˜é‡æ•°æ®ï¼Œæ‰€æœ‰å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(å…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
):
    """
    æ‰§è¡Œè¿ç»­å˜é‡ç›¸å…³æ€§æ£€éªŒï¼Œç”¨äºæ£€éªŒå¤šä¸ªè¿ç»­å˜é‡ä¹‹é—´çš„çº¿æ€§ç›¸å…³æ€§
    """
    return perform_continuous_independence_test(data, var_names)

@mcp.tool()
def perform_fisher_discriminant_analysis_tool(
    groups_data: List[float] = Field(..., description="å¤šç»„æ ·æœ¬æ•°æ®ï¼Œæ‰€æœ‰ç»„å’Œå˜é‡çš„å€¼æŒ‰ç»„å’Œå˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(å…ˆæ”¾ç»„1çš„ X1ã€X2...ï¼Œå†æ”¾ç»„2çš„X1ã€X2...)"),
    group_names: List[str] = Field(..., description="ç»„åç§°åˆ—è¡¨"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
):
    """
    æ‰§è¡ŒFisheråˆ¤åˆ«åˆ†æï¼Œç”¨äºå¯»æ‰¾æœ€èƒ½åŒºåˆ†ä¸åŒç»„çš„çº¿æ€§ç»„åˆ
    """
    return perform_fisher_discriminant_analysis(groups_data, group_names, var_names)

@mcp.tool()
def perform_distance_discriminant_analysis_tool(
    groups_data: List[float] = Field(..., description="å¤šç»„æ ·æœ¬æ•°æ®ï¼Œæ‰€æœ‰ç»„å’Œå˜é‡çš„å€¼æŒ‰ç»„å’Œå˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(å…ˆæ”¾ç»„1çš„ X1ã€X2...ï¼Œå†æ”¾ç»„2çš„X1ã€X2...)"),
    group_names: List[str] = Field(..., description="ç»„åç§°åˆ—è¡¨"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
    test_data: List[float] = Field(None, description="å¾…åˆ¤åˆ«æ ·æœ¬æ•°æ®(å¯é€‰)ï¼Œæ‰€æœ‰å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(å…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
):
    """
    æ‰§è¡Œè·ç¦»åˆ¤åˆ«åˆ†æï¼ŒåŸºäºé©¬æ°è·ç¦»è¿›è¡Œåˆ†ç±»åˆ¤åˆ«
    """
    return perform_distance_discriminant_analysis(groups_data, group_names, var_names, test_data)

@mcp.tool()
def perform_bayes_discriminant_analysis_tool(
    groups_data: List[float] = Field(..., description="å¤šç»„æ ·æœ¬æ•°æ®ï¼Œæ‰€æœ‰ç»„å’Œå˜é‡çš„å€¼æŒ‰ç»„å’Œå˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(å…ˆæ”¾ç»„1çš„ X1ã€X2...ï¼Œå†æ”¾ç»„2çš„X1ã€X2...)"),
    group_names: List[str] = Field(..., description="ç»„åç§°åˆ—è¡¨"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
    test_data: List[float] = Field(None, description="å¾…åˆ¤åˆ«æ ·æœ¬æ•°æ®(å¯é€‰)ï¼Œæ‰€æœ‰å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(å…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    prior_probabilities: List[float] = Field(None, description="å…ˆéªŒæ¦‚ç‡åˆ—è¡¨(å¯é€‰)ï¼Œé•¿åº¦åº”ä¸ç»„æ•°ç›¸åŒ"),
):
    """
    æ‰§è¡Œè´å¶æ–¯åˆ¤åˆ«åˆ†æï¼ŒåŸºäºè´å¶æ–¯å®šç†å’Œå¤šå…ƒæ­£æ€åˆ†å¸ƒå‡è®¾è¿›è¡Œåˆ†ç±»åˆ¤åˆ«
    """
    return perform_bayes_discriminant_analysis(groups_data, group_names, var_names, test_data, prior_probabilities)

@mcp.tool()
def perform_generalized_square_distance_discriminant_analysis_tool(
    groups_data: List[float] = Field(..., description="å¤šç»„æ ·æœ¬æ•°æ®ï¼Œæ‰€æœ‰ç»„å’Œå˜é‡çš„å€¼æŒ‰ç»„å’Œå˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(å…ˆæ”¾ç»„1çš„ X1ã€X2...ï¼Œå†æ”¾ç»„2çš„X1ã€X2...)"),
    group_names: List[str] = Field(..., description="ç»„åç§°åˆ—è¡¨"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
    test_data: List[float] = Field(None, description="å¾…åˆ¤åˆ«æ ·æœ¬æ•°æ®(å¯é€‰)ï¼Œæ‰€æœ‰å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(å…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
):
    """
    æ‰§è¡Œå¹¿ä¹‰å¹³æ–¹è·ç¦»åˆ¤åˆ«åˆ†æï¼Œè€ƒè™‘å„ç»„åæ–¹å·®çŸ©é˜µä¸ç­‰çš„æƒ…å†µè¿›è¡Œåˆ†ç±»åˆ¤åˆ«
    """
    return perform_generalized_square_distance_discriminant_analysis(groups_data, group_names, var_names, test_data)

@mcp.tool()
def perform_stepwise_discriminant_analysis_tool(
    groups_data: List[float] = Field(..., description="å¤šç»„æ ·æœ¬æ•°æ®ï¼Œæ‰€æœ‰ç»„å’Œå˜é‡çš„å€¼æŒ‰ç»„å’Œå˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(å…ˆæ”¾ç»„1çš„ X1ã€X2...ï¼Œå†æ”¾ç»„2çš„X1ã€X2...)"),
    group_names: List[str] = Field(..., description="ç»„åç§°åˆ—è¡¨"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
    method: str = Field("wilks", description="é€æ­¥é€‰æ‹©æ–¹æ³•: 'wilks'(Wilks' Lambda), 'f'(Fæ£€éªŒ)"),
    significance_level_enter: float = Field(0.05, description="å˜é‡è¿›å…¥æ¨¡å‹çš„æ˜¾è‘—æ€§æ°´å¹³"),
    significance_level_remove: float = Field(0.10, description="å˜é‡ç§»å‡ºæ¨¡å‹çš„æ˜¾è‘—æ€§æ°´å¹³"),
):
    """
    æ‰§è¡Œé€æ­¥åˆ¤åˆ«åˆ†æï¼Œé€šè¿‡é€æ­¥é€‰æ‹©å˜é‡æ„å»ºæœ€ä¼˜åˆ¤åˆ«å‡½æ•°
    """
    return perform_stepwise_discriminant_analysis(
        groups_data, 
        group_names, 
        var_names, 
        method, 
        significance_level_enter, 
        significance_level_remove
    )

@mcp.tool()
def perform_kmeans_clustering_tool(
    data: List[float] = Field(..., description="æ ·æœ¬æ•°æ®ï¼Œæ‰€æœ‰å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
    n_clusters: int = Field(3, description="èšç±»æ•°é‡"),
    init_method: str = Field("k-means++", description="åˆå§‹åŒ–æ–¹æ³•: 'k-means++' æˆ– 'random'"),
    max_iter: int = Field(300, description="æœ€å¤§è¿­ä»£æ¬¡æ•°"),
    n_init: int = Field(10, description="è¿è¡Œç®—æ³•çš„æ¬¡æ•°ï¼Œè¿”å›æœ€å¥½çš„ç»“æœ"),
    random_state: Optional[int] = Field(None, description="éšæœºç§å­ï¼Œç”¨äºç»“æœå¯é‡ç°"),
):
    """
    æ‰§è¡ŒK-Meansèšç±»åˆ†æ
    """
    return perform_kmeans_clustering(data, var_names, n_clusters, init_method, max_iter, n_init, random_state)

@mcp.tool()
def perform_kmedoids_clustering_tool(
    data: List[float] = Field(..., description="æ ·æœ¬æ•°æ®ï¼Œæ‰€æœ‰å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
    n_clusters: int = Field(3, description="èšç±»æ•°é‡"),
    max_iter: int = Field(300, description="æœ€å¤§è¿­ä»£æ¬¡æ•°"),
    random_state: Optional[int] = Field(None, description="éšæœºç§å­ï¼Œç”¨äºç»“æœå¯é‡ç°"),
):
    """
    æ‰§è¡ŒK-Medoidsèšç±»åˆ†æ
    """
    return perform_kmedoids_clustering(data, var_names, n_clusters, max_iter, random_state)

@mcp.tool()
def perform_dbscan_clustering_tool(
    data: List[float] = Field(..., description="æ ·æœ¬æ•°æ®ï¼Œæ‰€æœ‰å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
    eps: float = Field(0.5, description="é‚»åŸŸåŠå¾„"),
    min_samples: int = Field(5, description="æ ¸å¿ƒç‚¹é‚»åŸŸä¸­çš„æœ€å°æ ·æœ¬æ•°"),
):
    """
    æ‰§è¡ŒDBSCANèšç±»åˆ†æ
    """
    return perform_dbscan_clustering(data, var_names, eps, min_samples)

@mcp.tool()
def perform_hierarchical_clustering_tool(
    data: List[float] = Field(..., description="æ ·æœ¬æ•°æ®ï¼Œæ‰€æœ‰å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
    n_clusters: int = Field(3, description="èšç±»æ•°é‡"),
    linkage_method: str = Field("ward", description="é“¾æ¥æ–¹æ³•: 'ward', 'complete', 'average', 'single'"),
):
    """
    æ‰§è¡Œå‡èšå¼å±‚æ¬¡èšç±»åˆ†æ
    """
    return perform_hierarchical_clustering(data, var_names, n_clusters, linkage_method)

@mcp.tool()
def perform_gmm_clustering_tool(
    data: List[float] = Field(..., description="æ ·æœ¬æ•°æ®ï¼Œæ‰€æœ‰å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
    n_components: int = Field(3, description="æ··åˆæˆåˆ†æ•°é‡ï¼ˆç›¸å½“äºèšç±»æ•°ï¼‰"),
    covariance_type: str = Field("full", description="åæ–¹å·®ç±»å‹: 'full', 'tied', 'diag', 'spherical'"),
    max_iter: int = Field(100, description="æœ€å¤§è¿­ä»£æ¬¡æ•°"),
    random_state: Optional[int] = Field(None, description="éšæœºç§å­ï¼Œç”¨äºç»“æœå¯é‡ç°"),
):
    """
    æ‰§è¡Œé«˜æ–¯æ··åˆæ¨¡å‹(GMM)èšç±»åˆ†æ
    """
    return perform_gmm_clustering(data, var_names, n_components, covariance_type, max_iter, random_state)

# æ·»åŠ ä¸»æˆåˆ†åˆ†æå·¥å…·å‡½æ•°
@mcp.tool()
def perform_pca_tool(
    data: List[float] = Field(..., description="æ ·æœ¬æ•°æ®ï¼Œæ‰€æœ‰å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
    n_components: Optional[int] = Field(None, description="ä¸»æˆåˆ†æ•°é‡ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä¿ç•™æ‰€æœ‰æˆåˆ†"),
    standardize: bool = Field(True, description="æ˜¯å¦æ ‡å‡†åŒ–æ•°æ®"),
):
    """
    æ‰§è¡Œä¸»æˆåˆ†åˆ†æ(PCA)
    """
    return perform_pca(data, var_names, n_components, standardize)

# æ·»åŠ å› å­åˆ†æå·¥å…·å‡½æ•°
@mcp.tool()
def perform_factor_analysis_tool(
    data: List[float] = Field(..., description="æ ·æœ¬æ•°æ®ï¼Œæ‰€æœ‰å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
    n_factors: Optional[int] = Field(None, description="å› å­æ•°é‡ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤æ–¹æ³•ç¡®å®š"),
    rotation: str = Field("varimax", description="å› å­æ—‹è½¬æ–¹æ³•: 'varimax', 'promax', None"),
    standardize: bool = Field(True, description="æ˜¯å¦æ ‡å‡†åŒ–æ•°æ®"),
):
    """
    æ‰§è¡Œå› å­åˆ†æ
    """
    return perform_factor_analysis(data, var_names, n_factors, rotation, standardize)

@mcp.tool()
def perform_correspondence_analysis_tool(
    observed_frequencies: List[int] = Field(..., description="è§‚æµ‹é¢‘æ•°è¡¨ï¼Œæ‰€æœ‰è¡Œçš„å€¼æŒ‰è¡Œæ‹¼æ¥æˆä¸€ç»´æ•°ç»„(å…ˆæ”¾ç¬¬1è¡Œçš„å€¼ï¼Œå†æ”¾ç¬¬2è¡Œçš„å€¼ï¼Œ...)"),
    row_labels: List[str] = Field(..., description="è¡Œæ ‡ç­¾åˆ—è¡¨"),
    col_labels: List[str] = Field(..., description="åˆ—æ ‡ç­¾åˆ—è¡¨"),
):
    """
    æ‰§è¡Œå¯¹åº”åˆ†æ
    """
    return perform_correspondence_analysis(observed_frequencies, row_labels, col_labels)

@mcp.tool()
def perform_canonical_correlation_analysis_tool(
    x_data: List[float] = Field(..., description="ç¬¬ä¸€ç»„å˜é‡æ•°æ®ï¼Œæ‰€æœ‰ç¬¬ä¸€ç»„å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    y_data: List[float] = Field(..., description="ç¬¬äºŒç»„å˜é‡æ•°æ®ï¼Œæ‰€æœ‰ç¬¬äºŒç»„å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    x_var_names: List[str] = Field(..., description="ç¬¬ä¸€ç»„å˜é‡åç§°åˆ—è¡¨"),
    y_var_names: List[str] = Field(..., description="ç¬¬äºŒç»„å˜é‡åç§°åˆ—è¡¨"),
    standardize: bool = Field(True, description="æ˜¯å¦æ ‡å‡†åŒ–æ•°æ®"),
):
    """
    æ‰§è¡Œå…¸å‹ç›¸å…³åˆ†æ
    """
    return perform_canonical_correlation_analysis(x_data, y_data, x_var_names, y_var_names, standardize)

@mcp.tool()
def perform_pls_regression_tool(
    x_data: List[float] = Field(..., description="è‡ªå˜é‡æ•°æ®ï¼Œæ‰€æœ‰è‡ªå˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    y_data: List[float] = Field(..., description="å› å˜é‡æ•°æ®ï¼Œæ‰€æœ‰å› å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    x_var_names: List[str] = Field(..., description="è‡ªå˜é‡åç§°åˆ—è¡¨"),
    y_var_names: List[str] = Field(..., description="å› å˜é‡åç§°åˆ—è¡¨"),
    n_components: Optional[int] = Field(None, description="æˆåˆ†æ•°é‡ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™è‡ªåŠ¨é€‰æ‹©"),
    standardize: bool = Field(True, description="æ˜¯å¦æ ‡å‡†åŒ–æ•°æ®"),
):
    """
    æ‰§è¡Œåæœ€å°äºŒä¹˜å›å½’åˆ†æ
    """
    return perform_pls_regression(x_data, y_data, x_var_names, y_var_names, n_components, standardize)

@mcp.tool()
def perform_time_series_analysis_tool(
    time_series: List[float] = Field(..., description="æ—¶é—´åºåˆ—æ•°æ®"),
    time_labels: List[str] = Field(..., description="æ—¶é—´æ ‡ç­¾åˆ—è¡¨"),
    model_type: str = Field("auto_arima", description="æ¨¡å‹ç±»å‹: 'auto_arima', 'sarima', 'exponential_smoothing', 'manual_arima'"),
    forecast_steps: int = Field(10, description="é¢„æµ‹æ­¥æ•°"),
    seasonal_period: Optional[int] = Field(None, description="å­£èŠ‚æ€§å‘¨æœŸï¼ˆå¦‚æœˆåº¦æ•°æ®ä¸º12ï¼Œå­£åº¦æ•°æ®ä¸º4ï¼‰"),
    order: Optional[List[int]] = Field(None, description="ARIMAæ¨¡å‹çš„(p,d,q)å‚æ•°ï¼Œæ ¼å¼ä¸º[p,d,q]"),
    seasonal_order: Optional[List[int]] = Field(None, description="å­£èŠ‚æ€§ARIMAæ¨¡å‹çš„(P,D,Q,s)å‚æ•°ï¼Œæ ¼å¼ä¸º[P,D,Q,s]"),
):
    """
    æ‰§è¡Œæ—¶é—´åºåˆ—åˆ†æ
    """
    return perform_time_series_analysis(time_series, time_labels, model_type, forecast_steps, seasonal_period, order, seasonal_order)

@mcp.tool()
def perform_time_series_preprocessing_tests_tool(
    time_series: List[float] = Field(..., description="æ—¶é—´åºåˆ—æ•°æ®"),
    time_labels: List[str] = Field(..., description="æ—¶é—´æ ‡ç­¾åˆ—è¡¨"),
    seasonal_period: Optional[int] = Field(None, description="å­£èŠ‚æ€§å‘¨æœŸï¼ˆå¦‚æœˆåº¦æ•°æ®ä¸º12ï¼Œå­£åº¦æ•°æ®ä¸º4ï¼‰"),
    test_types: List[str] = Field(["adf", "kpss", "normality", "autocorrelation"], description="è¦æ‰§è¡Œçš„æ£€éªŒç±»å‹åˆ—è¡¨: 'adf'(ADFå¹³ç¨³æ€§æ£€éªŒ), 'kpss'(KPSSå¹³ç¨³æ€§æ£€éªŒ), 'normality'(æ­£æ€æ€§æ£€éªŒ), 'autocorrelation'(è‡ªç›¸å…³æ£€éªŒ)"),
):
    """
    æ‰§è¡Œæ—¶é—´åºåˆ—é¢„å¤„ç†æ£€éªŒï¼Œç”¨äºåˆ¤æ–­æ—¶é—´åºåˆ—æ˜¯å¦é€‚åˆå»ºæ¨¡
    """
    return perform_time_series_preprocessing_tests(time_series, time_labels, seasonal_period, test_types)

@mcp.tool()
def perform_regularized_regression_tool(
    dependent_var: List[float] = Field(..., description="å› å˜é‡æ•°æ®"),
    independent_vars: List[float] = Field(..., description="è‡ªå˜é‡æ•°æ®ï¼Œæ‰€æœ‰è‡ªå˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨ï¼Œç¬¬ä¸€ä¸ªä¸ºå› å˜é‡åï¼Œåç»­ä¸ºè‡ªå˜é‡å"),
    method: str = Field("ridge", description="æ­£åˆ™åŒ–æ–¹æ³•: 'ridge'(å²­å›å½’), 'lasso'(å¥—ç´¢å›å½’), 'elastic_net'(å¼¹æ€§ç½‘ç»œ)"),
    alpha: float = Field(1.0, description="æ­£åˆ™åŒ–å¼ºåº¦å‚æ•°"),
    l1_ratio: float = Field(0.5, description="Elastic Netä¸­L1æ­£åˆ™åŒ–çš„æ¯”ä¾‹ (ä»…ç”¨äºelastic_netæ–¹æ³•)"),
    standardize: bool = Field(True, description="æ˜¯å¦æ ‡å‡†åŒ–æ•°æ®"),
    fit_intercept: bool = Field(True, description="æ˜¯å¦è®¡ç®—æˆªè·"),
):
    """
    æ‰§è¡Œæ­£åˆ™åŒ–å›å½’åˆ†æï¼ˆå²­å›å½’ã€å¥—ç´¢å›å½’ã€Elastic Netå›å½’ï¼‰
    """
    return perform_regularized_regression(dependent_var, independent_vars, var_names, method, alpha, l1_ratio, standardize, fit_intercept)

@mcp.tool()
def perform_generalized_linear_model_tool(
    dependent_var: List = Field(..., description="å› å˜é‡æ•°æ®"),
    independent_vars: List[float] = Field(..., description="è‡ªå˜é‡æ•°æ®ï¼Œæ‰€æœ‰è‡ªå˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨ï¼Œç¬¬ä¸€ä¸ªä¸ºå› å˜é‡åï¼Œåç»­ä¸ºè‡ªå˜é‡å"),
    model_type: str = Field("logistic", description="æ¨¡å‹ç±»å‹: 'logistic'(äºŒåˆ†ç±»é€»è¾‘å›å½’), 'multinomial'(å¤šé¡¹é€»è¾‘å›å½’), 'ordinal'(æœ‰åºé€»è¾‘å›å½’), 'poisson'(æ³Šæ¾å›å½’), 'negative_binomial'(è´ŸäºŒé¡¹å›å½’)"),
):
    """
    æ‰§è¡Œå¹¿ä¹‰çº¿æ€§æ¨¡å‹åˆ†æ
    """
    return perform_generalized_linear_model(dependent_var, independent_vars, var_names, model_type)

@mcp.tool()
def perform_quantile_regression_tool(
    dependent_var: List[float] = Field(..., description="å› å˜é‡æ•°æ®"),
    independent_vars: List[float] = Field(..., description="è‡ªå˜é‡æ•°æ®ï¼Œæ‰€æœ‰è‡ªå˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨ï¼Œç¬¬ä¸€ä¸ªä¸ºå› å˜é‡åï¼Œåç»­ä¸ºè‡ªå˜é‡å"),
    quantiles: List[float] = Field([0.25, 0.5, 0.75], description="åˆ†ä½æ•°åˆ—è¡¨ï¼Œæ¯ä¸ªå€¼åº”åœ¨0åˆ°1ä¹‹é—´"),
    alpha: float = Field(1.0, description="æ­£åˆ™åŒ–å¼ºåº¦å‚æ•°"),
    standardize: bool = Field(True, description="æ˜¯å¦æ ‡å‡†åŒ–æ•°æ®"),
):
    """
    æ‰§è¡Œåˆ†ä½æ•°å›å½’åˆ†æ
    """
    return perform_quantile_regression(dependent_var, independent_vars, var_names, quantiles, alpha, standardize)

@mcp.tool()
def perform_sem_tool(
    data: List[float] = Field(..., description="è§‚æµ‹æ•°æ®ï¼Œæ‰€æœ‰å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
    model_description: str = Field(..., description="æ¨¡å‹æè¿°å­—ç¬¦ä¸²ï¼Œä½¿ç”¨semopyè¯­æ³•å®šä¹‰æµ‹é‡æ¨¡å‹å’Œç»“æ„æ¨¡å‹"),
    group_var: Optional[str] = Field(None, description="åˆ†ç»„å˜é‡åç§°ï¼Œç”¨äºå¤šç»„åˆ†æ"),
):
    """
    æ‰§è¡Œç»“æ„æ–¹ç¨‹æ¨¡å‹åˆ†æ
    """
    return perform_sem(data, var_names, model_description, group_var)

@mcp.tool()
def perform_mds_tool(
    data: List[float] = Field(..., description="æ ·æœ¬æ•°æ®ï¼Œæ‰€æœ‰å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
    n_components: int = Field(2, description="é™ç»´åçš„ç»´åº¦æ•°"),
    metric: bool = Field(True, description="æ˜¯å¦ä½¿ç”¨åº¦é‡MDSï¼ŒTrueè¡¨ç¤ºç»å…¸MDSï¼ŒFalseè¡¨ç¤ºéåº¦é‡MDS"),
    n_init: int = Field(4, description="åˆå§‹åŒ–æ¬¡æ•°ï¼Œç”¨äºå¯»æ‰¾æœ€ä½³è§£"),
    max_iter: int = Field(300, description="æœ€å¤§è¿­ä»£æ¬¡æ•°"),
    dissimilarity: str = Field("euclidean", description="è·ç¦»åº¦é‡æ–¹æ³•: 'euclidean'(æ¬§æ°è·ç¦»), 'precomputed'(é¢„å…ˆè®¡ç®—çš„è·ç¦»çŸ©é˜µ)"),
    standardize: bool = Field(True, description="æ˜¯å¦æ ‡å‡†åŒ–æ•°æ®"),
):
    """
    æ‰§è¡Œå¤šç»´å°ºåº¦åˆ†æ(MDS)
    """
    return perform_mds(data, var_names, n_components, metric, n_init, max_iter, dissimilarity, standardize)

@mcp.tool()
def perform_umap_tool(
    data: List[float] = Field(..., description="æ ·æœ¬æ•°æ®ï¼Œæ‰€æœ‰å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
    n_neighbors: int = Field(15, description="é‚»å±…æ•°é‡ï¼Œæ§åˆ¶å±€éƒ¨ä¸å…¨å±€ç»“æ„çš„å¹³è¡¡"),
    n_components: int = Field(2, description="é™ç»´åçš„ç»´åº¦æ•°"),
    min_dist: float = Field(0.1, description="æœ€å°è·ç¦»ï¼Œæ§åˆ¶ç°‡çš„ç´§å¯†ç¨‹åº¦"),
    metric: str = Field("euclidean", description="è·ç¦»åº¦é‡æ–¹æ³•"),
    random_state: Optional[int] = Field(42, description="éšæœºç§å­ï¼Œç”¨äºç»“æœå¯é‡ç°"),
    standardize: bool = Field(True, description="æ˜¯å¦æ ‡å‡†åŒ–æ•°æ®"),
):
    """
    æ‰§è¡ŒUMAPéçº¿æ€§é™ç»´
    """
    return perform_umap(data, var_names, n_neighbors, n_components, min_dist, metric, random_state, standardize)

@mcp.tool()
def perform_robust_regression_tool(
    dependent_var: List[float] = Field(..., description="å› å˜é‡æ•°æ®"),
    independent_vars: List[float] = Field(..., description="è‡ªå˜é‡æ•°æ®ï¼Œæ‰€æœ‰è‡ªå˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨ï¼Œç¬¬ä¸€ä¸ªä¸ºå› å˜é‡åï¼Œåç»­ä¸ºè‡ªå˜é‡å"),
    method: str = Field("ransac", description="ç¨³å¥å›å½’æ–¹æ³•: 'ransac'(RANSACå›å½’), 'huber'(Huberå›å½’)"),
    standardize: bool = Field(True, description="æ˜¯å¦æ ‡å‡†åŒ–æ•°æ®"),
    fit_intercept: bool = Field(True, description="æ˜¯å¦è®¡ç®—æˆªè·"),
    min_samples: Optional[int] = Field(None, description="RANSACç®—æ³•ä¸­éšæœºæ ·æœ¬çš„æœ€å°æ•°é‡"),
    residual_threshold: Optional[float] = Field(None, description="RANSACç®—æ³•ä¸­æ ·æœ¬è¢«è§†ä¸ºå†…ç‚¹çš„æœ€å¤§æ®‹å·®"),
    max_trials: int = Field(100, description="RANSACç®—æ³•çš„æœ€å¤§è¿­ä»£æ¬¡æ•°"),
    epsilon: float = Field(1.35, description="Huberå›å½’çš„å‚æ•°ï¼Œå†³å®šå¯¹å¼‚å¸¸å€¼çš„æ•æ„Ÿåº¦"),
    alpha: float = Field(0.0001, description="Huberå›å½’çš„æ­£åˆ™åŒ–å¼ºåº¦"),
):
    """
    æ‰§è¡Œç¨³å¥å›å½’åˆ†æ
    """
    return perform_robust_regression(
        dependent_var, independent_vars, var_names, method, standardize, fit_intercept,
        min_samples, residual_threshold, max_trials, epsilon, alpha
    )

@mcp.tool()
def perform_hdbscan_clustering_tool(
    data: List[float] = Field(..., description="æ ·æœ¬æ•°æ®ï¼Œæ‰€æœ‰å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
    min_cluster_size: int = Field(5, description="å½¢æˆç°‡æ‰€éœ€çš„æœ€å°æ ·æœ¬æ•°"),
    min_samples: Optional[int] = Field(None, description="æ ¸å¿ƒç‚¹é‚»åŸŸä¸­çš„æœ€å°æ ·æœ¬æ•°ï¼Œå¦‚æœä¸ºNoneåˆ™é»˜è®¤ç­‰äºmin_cluster_size"),
    cluster_selection_method: str = Field("eom", description="ç°‡é€‰æ‹©æ–¹æ³•: 'eom'(è¶…é¢è´¨é‡ç®—æ³•), 'leaf'(å¶ç°‡é€‰æ‹©)"),
    allow_single_cluster: bool = Field(False, description="æ˜¯å¦å…è®¸å°†æ‰€æœ‰ç‚¹å½’ä¸ºä¸€ä¸ªç°‡"),
    alpha: float = Field(1.0, description="ç”¨äºè®¡ç®—ä¸ç¨³å®šæ€§çš„å‚æ•°"),
    metric: str = Field("euclidean", description="è·ç¦»åº¦é‡æ–¹æ³•"),
    standardize: bool = Field(True, description="æ˜¯å¦æ ‡å‡†åŒ–æ•°æ®"),
):
    """
    æ‰§è¡ŒHDBSCANèšç±»åˆ†æ
    """
    return perform_hdbscan_clustering(
        data, var_names, min_cluster_size, min_samples, cluster_selection_method, 
        allow_single_cluster, alpha, metric, standardize
    )

@mcp.tool()
def perform_time_series_cointegration_granger_tests_tool(
    time_series_list: List[float] = Field(..., description="æ—¶é—´åºåˆ—æ•°æ®ï¼Œæ‰€æœ‰æ—¶é—´åºåˆ—çš„å€¼æŒ‰æ—¶é—´åºåˆ—æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œæ—¶é—´åºåˆ—1ã€å†æ”¾æ—¶é—´åºåˆ—2 ...)"),
    series_names: List[str] = Field(..., description="æ—¶é—´åºåˆ—åç§°åˆ—è¡¨"),
    max_lag: int = Field(5, description="Grangerå› æœæ£€éªŒçš„æœ€å¤§æ»åé˜¶æ•°"),
    significance_level: float = Field(0.05, description="æ˜¾è‘—æ€§æ°´å¹³"),
):
    """
    æ‰§è¡Œæ—¶é—´åºåˆ—åæ•´æ£€éªŒå’ŒGrangerå› æœæ£€éªŒ
    """
    return perform_time_series_cointegration_granger_tests(
        time_series_list, series_names, max_lag, significance_level
    )

@mcp.tool()
def perform_data_standardization_tool(
    data: List[float] = Field(..., description="æ ·æœ¬æ•°æ®ï¼Œæ‰€æœ‰å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
    method: str = Field("zscore", description="æ ‡å‡†åŒ–æ–¹æ³•: 'zscore'(Z-scoreæ ‡å‡†åŒ–), 'minmax'(Min-Maxæ ‡å‡†åŒ–)"),
    feature_range: List[float] = Field([0, 1], description="Min-Maxæ ‡å‡†åŒ–çš„ç›®æ ‡èŒƒå›´ï¼Œæ ¼å¼ä¸º[min, max]"),
):
    """
    æ‰§è¡Œæ•°æ®æ ‡å‡†åŒ–ï¼ˆZ-scoreæ ‡å‡†åŒ–æˆ–Min-Maxæ ‡å‡†åŒ–ï¼‰
    """
    return perform_data_standardization(data, var_names, method, feature_range)

@mcp.tool()
def perform_multicollinearity_diagnosis_tool(
    independent_vars: List[float] = Field(..., description="è‡ªå˜é‡æ•°æ®ï¼Œæ‰€æœ‰è‡ªå˜é‡çš„å€¼æŒ‰è‡ªå˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="è‡ªå˜é‡åç§°åˆ—è¡¨"),
    vif_threshold: float = Field(5.0, description="VIFé˜ˆå€¼ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦å­˜åœ¨å¤šé‡å…±çº¿æ€§"),
):
    """
    æ‰§è¡Œå¤šé‡å…±çº¿æ€§è¯Šæ–­ï¼ˆæ–¹å·®è†¨èƒ€å› å­VIFåˆ†æï¼‰
    """
    return perform_multicollinearity_diagnosis(independent_vars, var_names, vif_threshold)

@mcp.tool()
def perform_mixed_effects_model_tool(
    dependent_var: List[float] = Field(..., description="å› å˜é‡æ•°æ®"),
    independent_vars: List[float] = Field(..., description="å›ºå®šæ•ˆåº”è‡ªå˜é‡æ•°æ®ï¼Œæ‰€æœ‰å›ºå®šæ•ˆåº”è‡ªå˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    random_effects_vars: List[float] = Field(..., description="éšæœºæ•ˆåº”å˜é‡æ•°æ®ï¼Œæ‰€æœ‰éšæœºæ•ˆåº”å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    grouping_vars: List[float] = Field(..., description="åˆ†ç»„å˜é‡æ•°æ®ï¼Œæ‰€æœ‰åˆ†ç»„å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨ï¼Œç¬¬ä¸€ä¸ªä¸ºå› å˜é‡åï¼Œåç»­ä¸ºå›ºå®šæ•ˆåº”è‡ªå˜é‡å"),
    random_effects_names: List[str] = Field(..., description="éšæœºæ•ˆåº”å˜é‡åç§°åˆ—è¡¨"),
    grouping_names: List[str] = Field(..., description="åˆ†ç»„å˜é‡åç§°åˆ—è¡¨"),
    fit_method: str = Field("ml", description="æ‹Ÿåˆæ–¹æ³•: 'ml'(æœ€å¤§ä¼¼ç„¶), 'reml'(å—é™æœ€å¤§ä¼¼ç„¶)"),
):
    """
    æ‰§è¡Œæ··åˆæ•ˆåº”æ¨¡å‹åˆ†æï¼ˆMixed Effects Models / Hierarchical Modelsï¼‰
    """
    return perform_mixed_effects_model(
        dependent_var, independent_vars, random_effects_vars, grouping_vars,
        var_names, random_effects_names, grouping_names, fit_method
    )

@mcp.tool()
def perform_multiple_imputation_tool(
    data: List[Union[float, None]] = Field(..., description="æ•°æ®ï¼Œæ‰€æœ‰å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)ï¼Œç¼ºå¤±å€¼ç”¨nullè¡¨ç¤º"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
    method: str = Field("mice", description="æ’è¡¥æ–¹æ³•: 'mice'(å¤šé‡æ’è¡¥), 'mean'(å‡å€¼æ’è¡¥), 'median'(ä¸­ä½æ•°æ’è¡¥), 'mode'(ä¼—æ•°æ’è¡¥), 'knn'(Kè¿‘é‚»æ’è¡¥)"),
    n_imputations: int = Field(5, description="æ’è¡¥æ¬¡æ•°ï¼Œä»…å¯¹'mice'æ–¹æ³•æœ‰æ•ˆ"),
    random_state: Optional[int] = Field(None, description="éšæœºç§å­ï¼Œç”¨äºç»“æœå¯é‡ç°"),
):
    """
    æ‰§è¡Œç¼ºå¤±å€¼å¤šé‡æ’è¡¥åˆ†æ
    """
    return perform_multiple_imputation(data, var_names, method, n_imputations, random_state)

@mcp.tool()
def perform_survival_analysis_tool(
    time_var: List[float] = Field(..., description="æ—¶é—´å˜é‡"),
    event_var: List[int] = Field(..., description="äº‹ä»¶æŒ‡ç¤ºå˜é‡ï¼ˆ1è¡¨ç¤ºäº‹ä»¶å‘ç”Ÿï¼Œ0è¡¨ç¤ºåˆ å¤±ï¼‰"),
    group_var: Optional[List[int]] = Field(None, description="åˆ†ç»„å˜é‡ï¼ˆç”¨äºKaplan-Meieræ›²çº¿å’ŒLog-rankæ£€éªŒï¼‰"),
    covariates: Optional[List[float]] = Field(None, description="åå˜é‡æ•°æ®ï¼Œæ‰€æœ‰åå˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    covariate_names: Optional[List[str]] = Field(None, description="åå˜é‡åç§°åˆ—è¡¨"),
    confidence_level: float = Field(0.95, description="ç½®ä¿¡åŒºé—´æ°´å¹³ï¼Œå¦‚0.95è¡¨ç¤º95%ç½®ä¿¡åŒºé—´"),
):
    """
    æ‰§è¡Œç”Ÿå­˜åˆ†æï¼ŒåŒ…æ‹¬Kaplan-Meierç”Ÿå­˜æ›²çº¿ä¼°è®¡ã€Log-rankæ£€éªŒå’ŒCoxæ¯”ä¾‹é£é™©æ¨¡å‹
    """
    return perform_survival_analysis(time_var, event_var, group_var, covariates, covariate_names, confidence_level)

@mcp.tool()
def perform_causal_inference_tool(
    data: List[float] = Field(..., description="æ ·æœ¬æ•°æ®ï¼Œæ‰€æœ‰å˜é‡çš„å€¼æŒ‰å˜é‡æ‹¼æ¥æˆä¸€ç»´æ•°ç»„(åˆ—ä¼˜å…ˆï¼Œå…ˆæ”¾å®Œ X1ã€å†æ”¾ X2 ...)"),
    var_names: List[str] = Field(..., description="å˜é‡åç§°åˆ—è¡¨"),
    treatment_var: str = Field(..., description="å¤„ç†å˜é‡åç§°"),
    outcome_var: str = Field(..., description="ç»“æœå˜é‡åç§°"),
    confounding_vars: List[str] = Field(..., description="æ··æ‚å˜é‡åç§°åˆ—è¡¨"),
    method: str = Field("ipw", description="å› æœæ¨æ–­æ–¹æ³•: 'ipw'(é€†æ¦‚ç‡åŠ æƒ), 'matching'(åŒ¹é…), 'regression'(å›å½’è°ƒæ•´)"),
    bootstrap_samples: int = Field(1000, description="BootstrapæŠ½æ ·æ¬¡æ•°ï¼Œç”¨äºè®¡ç®—ç½®ä¿¡åŒºé—´"),
    random_state: Optional[int] = Field(None, description="éšæœºç§å­ï¼Œç”¨äºç»“æœå¯é‡ç°"),
):
    """
    æ‰§è¡Œå› æœæ¨æ–­åˆ†æ
    """
    return perform_causal_inference(data, var_names, treatment_var, outcome_var, confounding_vars, method, bootstrap_samples, random_state)

@mcp.tool()
def perform_nonparametric_regression_tool(
    x_data: List[float] = Field(..., description="è‡ªå˜é‡æ•°æ®"),
    y_data: List[float] = Field(..., description="å› å˜é‡æ•°æ®"),
    method: str = Field("loess", description="éå‚æ•°å›å½’æ–¹æ³•: 'loess'(å±€éƒ¨åŠ æƒå›å½’), 'spline'(æ ·æ¡å›å½’)"),
    loess_frac: float = Field(0.3, description="LOESSæ–¹æ³•ä¸­ç”¨äºå±€éƒ¨å›å½’çš„çª—å£å¤§å°æ¯”ä¾‹ï¼Œå€¼è¶Šå¤§è¶Šå¹³æ»‘"),
    loess_it: int = Field(3, description="LOESSæ–¹æ³•çš„è¿­ä»£æ¬¡æ•°"),
    spline_degree: int = Field(3, description="æ ·æ¡å›å½’çš„å¤šé¡¹å¼é˜¶æ•°"),
    spline_smooth_factor: Optional[float] = Field(None, description="æ ·æ¡å›å½’çš„å¹³æ»‘å› å­ï¼Œå€¼è¶Šå¤§è¶Šå¹³æ»‘ï¼ŒNoneè¡¨ç¤ºè‡ªåŠ¨é€‰æ‹©"),
    confidence_level: float = Field(0.95, description="ç½®ä¿¡åŒºé—´æ°´å¹³ï¼Œå¦‚0.95è¡¨ç¤º95%ç½®ä¿¡åŒºé—´"),
):
    """
    æ‰§è¡Œéå‚æ•°/åŠå‚æ•°å›å½’åˆ†æï¼ˆLOESS/LOWESSã€æ ·æ¡å›å½’ï¼‰
    """
    return perform_nonparametric_regression(x_data, y_data, method, loess_frac, loess_it, 
                                          spline_degree, spline_smooth_factor, confidence_level)

# æ·»åŠ é™æ€æ–‡ä»¶è·¯ç”±
@mcp.custom_route("/generated_files/{filename:path}", methods=["GET"])
async def serve_static_files(request: Request):
    filename = request.path_params["filename"]
    file_path = os.path.join(OUTPUT_DIR, filename)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if os.path.exists(file_path):
        return FileResponse(file_path)
    else:
        # è¿”å›404å“åº”
        return JSONResponse({"error": "File not found"}, status_code=404)

# æ·»åŠ å¥åº·æ£€æŸ¥ç«¯ç‚¹
@mcp.custom_route("/health", methods=["GET"])
async def health_check(request: Request):
    return JSONResponse({
        "status": "healthy",
        "service": "multivariate-statistics-mcp-server",
        "version": "1.0.0"
    })


# # æ·»åŠ æ ¹è·¯å¾„å¥åº·æ£€æŸ¥ç«¯ç‚¹
# @mcp.custom_route("/", methods=["GET"])
# async def root_health_check(request: Request):
#     return JSONResponse({
#         "status": "healthy",
#         "service": "multivariate-statistics-mcp-server",
#         "version": "1.0.0"
#     })

def main():
    # å¯åŠ¨æ–‡ä»¶è‡ªåŠ¨æ¸…ç†ä»»åŠ¡
    start_cleanup_scheduler()
    
    # å¦‚æœç¯å¢ƒå˜é‡æŒ‡å®šäº†SERVER_HOSTï¼Œåˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡çš„å€¼
    host = os.environ.get("MCP_STATS_SERVER_HOST", SERVER_HOST)
    port = int(os.environ.get("MCP_STATS_SERVER_PORT", SERVER_PORT))
    transport = os.environ.get("MCP_STATS_SERVER_TRANSPORT", SERVER_TRANSPORT)
    
    print(f"Starting server on {host}:{port} with transport {transport}")
    print(f"Base URL: {BASE_URL}")
    
    mcp.run(
        transport=transport,
        host=host,
        port=port,
        path=SERVER_PATH,
        log_level=SERVER_LOG_LEVEL,
        # strict_accept=False,
    )


if __name__ == "__main__":
    main()